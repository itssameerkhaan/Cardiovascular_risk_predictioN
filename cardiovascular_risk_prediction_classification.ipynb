{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "q29F0dvdveiT",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itssameerkhaan/Cardiovascular_risk_predictioN/blob/main/cardiovascular_risk_prediction_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **`Cardiovascular Risk prediction`**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual / sameer khan\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Congenital heart disease** is one or more problems with the heart's structure that exist since birth. Congenital means that you're born with the condition. Congenital heart disease in adults and children can change the way blood flows through the heart.\n",
        "\n",
        "There are many different types of congenital heart defects. This article focuses on congenital heart disease in adults.\n",
        "\n",
        "Some types of congenital heart disease may be mild. But complex defects may cause life-threatening complications. However, advances in diagnosis and treatment continue to improve survival for those with congenital heart disease.\n",
        "\n",
        "People with congenital heart disease need lifelong medical care. Treatment may include regular checkups (watchful waiting), medications or surgery. If you have adult congenital heart disease, ask your health care provider how often you need a checkup.\n",
        "\n",
        "An Organized Dataset of individuals had been selected Keeping in mind their history of heart problems and in accordance with other medical conditions. Heart disease are the diverse conditions by which the heart is affected. According to World Health Organization (WHO), the greatest number of deaths in middle aged people are due to Cardiovascular diseases. We take a data source which is comprised of medical history of 3390 different patient of different age groups. This dataset gives us the much-needed information i.e. the medical attributes such as age, resting blood pressure, fasting sugar level etc. of the patient that helps us in detecting the patient that is diagnosed with any heart disease or not. This dataset contains 17 medical attributes of 3390 patients that helps us detecting if the patient is at risk of getting a heart disease or not and it helps us classify patients that are at risk of having a heart disease and that who are not at risk.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/itssameerkhan/Cardiovascular_risk_predictioN/tree/main"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Cardiovascular diseases (CVDs) are the major cause of mortality worldwide. According to WHO, 17.9 million people died from CVDs in 2019, accounting for 32% of all global fatalities.\n",
        "* Though CVDs cannot be treated, predicting the risk of the disease and taking the necessary precautions and medications can help to avoid severe symptoms and, in some cases, even death.\n",
        "* As a result, it is critical that we accurately predict the risk of heart disease in order to avert as many fatalities as possible."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -"
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "\n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "\n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "\n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "\n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "from plotly.tools import make_subplots\n",
        "from scipy.stats import shapiro\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.feature_selection import chi2\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import ttest_1samp\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score,roc_curve,auc\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.metrics import precision_recall_curve,precision_score,recall_score\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.model_selection import cross_val_predict,cross_val_score\n",
        "from prettytable import PrettyTable\n",
        "! pip install scikit-plot==0.3.7\n",
        "import scikitplot as skplt\n",
        "! pip install shap\n",
        "import shap\n",
        "from shap import TreeExplainer, Explanation\n",
        "plt.style.use('ggplot')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "i0_yEw8hjexC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/itssameerkhan/Cardiovascular_risk_predictioN.git"
      ],
      "metadata": {
        "id": "07RJUo5i2Vmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "dataset=pd.read_csv('/content/Cardiovascular_risk_predictioN/data_cardiovascular_risk.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "dataset.sample(5)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"Number of row :-\",dataset.shape[0])\n",
        "print(\"Number of columns :-\",dataset.shape[1])"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(\"Numbr of duplicate value :-  \",dataset.duplicated().sum())"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(dataset.isnull(),cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this dataset , total number of Rows are 3390 and columns are 17 . This dataset have total 15 numeric columns and 2 (sex, is_smoking) are objective columns. zero '0' duplicate value. Total number of null value is 510 and { education - 87, cigsperDay-22, BPMeds-44, totChol-38, BMI-14, heartRate-1, glucose-304}"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "dataset.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. id= identity\n",
        "2. age= how old you are.\n",
        "3. education= the teaching or training of people.\n",
        "4. sex= male or female (1= male, 0=female).\n",
        "5. is_smoking= smoking or not (1= smoking, 0= not smoking).\n",
        "6. cigsPerDay= cigarette consumption in a day.\n",
        "7. BPMeds= whether taking BP meds or not.\n",
        "8. prevalentStroke= petient have history of stroke.\n",
        "9. prevalentHyp= patient have history of hypertension.\n",
        "10. diabetes= patient have diabetes or not.\n",
        "11. totChol= cholestrol measure.\n",
        "12. sysBP= systolic bloood pressure.\n",
        "13. diaBP= disystolic blood pressure.\n",
        "14. BMI= body mass index.\n",
        "15. heartRate= heart Rate meassure.\n",
        "16. glucose= body glucose meassure.\n",
        "17. TenYearCHD= 10-year risk of coronary heart disease have or not."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in dataset.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",dataset[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Here i am going to copy full dataset into df because i do analysis and data manipulation in df.`**"
      ],
      "metadata": {
        "id": "dyCAns9rUh3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "df=dataset.copy()\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Droping the education columns`**"
      ],
      "metadata": {
        "id": "A1IMfkTYJLil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. we all know that the education is not any factor through TenyearCHD (heart desies) is going to affected.\n",
        "2. this show that the education is not correlated with TenYearCHD therefore i drope the education columns."
      ],
      "metadata": {
        "id": "nHyqWmuEU4Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['education','TenYearCHD']].corr()"
      ],
      "metadata": {
        "id": "00XWNyHX5nnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['education'],inplace=True)"
      ],
      "metadata": {
        "id": "tCAYAkGwJlLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "Wizb-NojVrT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Creating a new column 'sys-dia'`**"
      ],
      "metadata": {
        "id": "AEPGmU1nV6tu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are going to create a column 'sys-dia' which store the fraction of sysBP and diaBP (sys-dia=sysBP/diaBP). this makes the analysis easear .\n",
        "\n",
        "Here the boudary of normal value is (this is the maximum normal value of sysBP\n",
        " :120/ the maximum normal value of diaBP  :80 = maximum normal value of sys-dia is  :1.5)"
      ],
      "metadata": {
        "id": "9lD1Zq9VWRz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the new column sys-dia.\n",
        "df['sys-dia']=round(df['sysBP']/df['diaBP'],2)"
      ],
      "metadata": {
        "id": "BvjIP2ejV4Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Drop the education column.\n",
        "2. Creat a new column name is sys-dia which store the fraction of sysBP and diaBP.\n",
        "\n",
        "I do not see any other manipulation in this dataset."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1  **`: Nmber of paitents who having TenYearCHD or Not having.`**"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#what is the number of paitent who have TenYearCHD problem and who have not .\n",
        "ax=df.TenYearCHD.value_counts().plot(kind='bar')\n",
        "for i in ax.containers:\n",
        "    ax.bar_label(i,)\n",
        "plt.title('Having TenYearCHD or Not',fontsize=15,fontweight='bold')\n",
        "plt.xlabel('1= YES AND 0= NO',fontsize=10)\n",
        "plt.ylabel('Number of paitents',fontsize=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows the number of paitent who have TenYearCHD problem and who have not ."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of 3300 paitents 511 having TenYearCHD problem and 2879 are away from this disease."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ratio of having disease and ant not having disease is 5:28. this show that not having disease is very high. this show the positive impact."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 : **`Range percentage of age having disease.`**"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "data_TYCHD=df[(df.TenYearCHD==1)]\n",
        "name=['AGE(40<age<=50)','AGE(50<age<=60)','AGE(60<age<=70)','AGE(age<40)']\n",
        "per=[round(len(data_TYCHD[(df.age>40)&(df.age<=50)])/len(data_TYCHD)*100,2),\n",
        "     round(len(data_TYCHD[(df.age>50)&(df.age<=60)])/len(data_TYCHD)*100,2),\n",
        "     round(len(data_TYCHD[(df.age>60)&(df.age<=70)])/len(data_TYCHD)*100,2),\n",
        "     round(len(data_TYCHD[(df.age<40)])/len(data_TYCHD)*100,2)]"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(per,labels=name,explode=(0.05,0.1,0,0),autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hkCc-dBVbLSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart show the range of age whcih have how many parcentage of paitents having disease."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this chart shows that the age between 50 and 60 having 41.5% of total number of paitents and between 60 and 70 26.8% and bellow 40 is 38% and above 70 is 0%."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "YES because this chart show that the persion who is in 50s and 60s having high risk in TenYearCHD disease."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 : **`Number of people who smoke or don't smoke.`**"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "ind=df.is_smoking[df.TenYearCHD==0].value_counts().index\n",
        "smok_value=df.is_smoking[df.TenYearCHD==0].value_counts().values\n",
        "ind2=df.is_smoking[df.TenYearCHD==1].value_counts().index\n",
        "smok_value2=df.is_smoking[df.TenYearCHD==1].value_counts().values"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax=plt.subplots()\n",
        "fig1=ax.bar(ind,smok_value)\n",
        "fig1[0].set_color('green')\n",
        "fig1[1].set_color('green')\n",
        "for index,value in enumerate(smok_value):\n",
        "  ax.text(x=index,y=value+10,s=value,fontdict={'color':'green','fontweight':'bold'})\n",
        "fig2=ax.bar(ind,smok_value2)\n",
        "fig2[0].set_color('gray')\n",
        "fig2[1].set_color('gray')\n",
        "for index2,value2 in enumerate(smok_value2):\n",
        "  ax.text(x=index2,y=value2+100,s=value2,fontdict={'color':'gray','fontweight':'bold'})\n",
        "plt.title('Smoker or Not',fontweight='bold')\n",
        "ax.text(x=1.6,y=1300,s='Where TenYearCHD==0',fontdict={'color':'green','fontweight':'bold'})\n",
        "ax.text(x=1.6,y=1210,s='Where TenYearCHD==1',fontdict={'color':'gray','fontweight':'bold'})"
      ],
      "metadata": {
        "id": "-lw0jbBw7sWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of people who smoke or don't smoke."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that the number of patients who smoke and also having **TenYearCHD==yes** .\n",
        "1. YES : 236 people are smokers and also they have tenYearCHD.\n",
        "2. NO : 275 people are not smokers and but they have tenYearCHD.\n",
        "\n",
        "\n",
        "---\n",
        "Here we can see that the number of people who smoke and dont smoke and also not having **TenYearCHD==no**\n",
        "1. YES : 1412 people are smoker .\n",
        "2. NO : 1467 people are not smoker.\n",
        "\n",
        "\n",
        "\n",
        "this chart show that 274 of patients are smoker and 234 are not .\n",
        "\n",
        "Smoking increase the chances of getting TenYearCHD disease."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes, because we know through this chart , smoking is not good for our helth."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4  : **`This chart shows what percantage of petaint are smoking how many cigarettes`**"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "CHD_data=df[dataset.TenYearCHD==1]\n",
        "cig_range=['More than 20','More than 10','More than 5','More than 0']\n",
        "cig_value=[len(CHD_data[CHD_data.cigsPerDay>=20]),len(CHD_data[(CHD_data.cigsPerDay>=10)&(CHD_data.cigsPerDay<20)]),len(CHD_data[(CHD_data.cigsPerDay>=5)&(CHD_data.cigsPerDay<10)]),len(CHD_data[(CHD_data.cigsPerDay>0)&(CHD_data.cigsPerDay<5)])]"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(cig_value,labels=cig_range,autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90,explode=(0.1,0,0,0))\n",
        "plt.title('what percentage of petaint are smoking how many cigarettes',fontsize=10,fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F_HwigJZcoyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart shows what percantage of petaint are smoking how many cigarettes"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this chart shows thata the percantage fo petaint who conssume how many cigarettes in a daay.\n",
        "1. 66.2 % of petaint conssume more than 20 cigarettes in a day.\n",
        "2. 17.2 % of petaint conssume mote than 10 cigarettes in a day.\n",
        "3. 9.9 % of petaint conssume more than 5 cigarettes in a day.\n",
        "4. 6.9 % of petaint conssume mote than 1 to 4 cigarettes in a day."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More cigarettes more chance to infected by heart dessies."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 : **`Number of people who are taking or not taking Blood Pressure medicine `**"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "BPM_ind=df.BPMeds.value_counts().index\n",
        "BPM_value=df.BPMeds.value_counts().values"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax=sns.barplot(x=BPM_ind,y=BPM_value)\n",
        "for i in ax.containers:\n",
        "    ax.bar_label(i,)\n",
        "ax.set_title('Taking or not taking BP medicine',fontsize=10,fontweight='bold')\n",
        "ax.set_xlabel('1=YES , 0=NO',fontsize=10,fontweight='bold')"
      ],
      "metadata": {
        "id": "G3EqZqSUdfkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart shows the number of those people who are taking or not taking blood pressure medicine."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can clearly see that out of 3389 only 121 people has taking the BP medicine and 3268 are not taking any kind of medicine ."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This columns not have a balance data. therefore it not afecting the resuslt efectevly."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 : **`This show the prevalent hypertension and strok where TenYearCHD==NO and TenYearCHD==YES`**"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "stroke_name=['NO','YES']\n",
        "stroke_value=df.prevalentStroke[df.TenYearCHD==0].value_counts().values\n",
        "CHD_stroke_value=df.prevalentStroke[df.TenYearCHD==1].value_counts().values\n",
        "fig, ax=plt.subplots()\n",
        "fig=ax.bar(stroke_name,stroke_value)\n",
        "for index,data in enumerate(stroke_value):\n",
        "  ax.text(x=index, y=data+40,s=data,ha='center',fontdict={'color':'blue','fontweight':'bold'})\n",
        "fig[0].set_color('blue')\n",
        "fig[1].set_color('blue')\n",
        "fig2=ax.bar(stroke_name,CHD_stroke_value)\n",
        "for index,data in enumerate(CHD_stroke_value):\n",
        "  ax.text(x=index, y=data+180,s=data,ha='center',fontdict={'color':'black','fontweight':'bold'})\n",
        "fig2[0].set_color('black')\n",
        "fig2[1].set_color('black')\n",
        "ax.text(x=0.7,y=2500,s='TenYearCHD==1 (YES)',fontdict={'color':'black','fontweight':'bold','fontsize':7})\n",
        "ax.text(x=0.7,y=2300,s='TenYearCHD==0 (NO)',fontdict={'color':'blue','fontweight':'bold','fontsize':7})\n",
        "plt.title('Number of prevalentSroke',fontsize=10,fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stroke_name=['NO','YES']\n",
        "hyp_value=df.prevalentHyp[df.TenYearCHD==0].value_counts().values\n",
        "CHD_hyp_value=df.prevalentHyp[df.TenYearCHD==1].value_counts().values\n",
        "fig, ax=plt.subplots()\n",
        "fig=ax.bar(stroke_name,hyp_value)\n",
        "for index,data in enumerate(hyp_value):\n",
        "  ax.text(x=index, y=data+40,s=data,ha='center',fontdict={'color':'gray','fontweight':'bold'})\n",
        "fig[0].set_color('gray')\n",
        "fig[1].set_color('gray')\n",
        "fig2=ax.bar(stroke_name,CHD_hyp_value)\n",
        "for index,data in enumerate(CHD_hyp_value):\n",
        "  ax.text(x=index, y=data+180,s=data,ha='center',fontdict={'color':'#66023C','fontweight':'bold'})\n",
        "fig2[0].set_color('#66023C')\n",
        "fig2[1].set_color('#66023C')\n",
        "ax.text(x=0.7,y=1700,s='TenYearCHD==1 (YES)',fontdict={'color':'#66023C','fontweight':'bold','fontsize':7})\n",
        "ax.text(x=0.7,y=1550,s='TenYearCHD==0 (NO)',fontdict={'color':'gray','fontweight':'bold','fontsize':7})\n",
        "plt.title('Number of prevalentHyp',fontsize=10,fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xuy7E5ZKm6u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This show the prevalent hypertension and strok where TenYearCHD==NO and TenYearCHD==YES"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREVALENT STROKE**\n",
        "\n",
        "Number of people where prevalent stroke is Yes or No in dataset where **TenYearCHD==0 (no)**\n",
        "1. 2867 people are not having any prevalent stroke.\n",
        "2. only 12 people are having prevalent stroke.\n",
        "\n",
        "Number of people where prevalent stroke is Yes or No in dataset where **TenYearCHD==1 (yes)**\n",
        "1. 501 people are not having any prevalent stroke.\n",
        "2. 10 peaple are having prevalent stroke.\n",
        "---\n",
        "**PREVALENT HYPERTENSION**\n",
        "\n",
        "Number of people where prevalent hypertension is Yes or No in dataset where **TenYearCHD==0 (no)**\n",
        "1. 2065 people are not havind any prevalent hypertension.\n",
        "2. 814 people are having prevalent hypertension.\n",
        "\n",
        "Number of people where prevalent hypertension is yes or no in dataset where **TenYearCHD==1 (yes)**\n",
        "1. 256 people are not having prevalent hypertension.\n",
        "2. 255 people are having prevalent hypertension.\n",
        "\n"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes, prevalent hypertension is higher than prevalent stroke in dataset where TenYearCHD ==1 (yes)\n"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 : **`Number of diabetic petiets, who have glucose lavel greater or less than 125 and also having TenYearCHD==1(YES).`**"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "#ploting number of the diabetic people\n",
        "dia_ind=['NO','YES']\n",
        "dia_value=df.diabetes.value_counts().values\n",
        "fig, ax=plt.subplots()\n",
        "fig=ax.bar(dia_ind,dia_value)\n",
        "for index,value in enumerate(dia_value):\n",
        "  ax.text(x=index,y=value+30,s=value)\n",
        "fig[0].set_color('green')\n",
        "fig[1].set_color('red')\n",
        "plt.title('Number of diabetic or non diabetic people',fontsize=10,fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "per_label=['TenYearCHD==1(YES) and glucose>=125','TenYearCHD==1(YES) and glucose<=125']\n",
        "per_value=[len(df[(df.diabetes==1)&(df.TenYearCHD==1)&(df.glucose>=125)]),len(df[(df.glucose<=125)&(df.diabetes==1)&(df.TenYearCHD==1)])]\n",
        "plt.pie(per_value,labels=per_label,autopct='%1.1f%%',explode=(0.1,0),shadow=0.5)\n",
        "plt.title('Percentage of diabetic petaints',fontsize=10,fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e236-41bT52L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of diabetic petiets who have glucose lavel greater or less than 125 and also having TenYearCHD==1(YES)."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. We can see that out of 3390 only 87 people are suffering from diabeteis.\n",
        "2. In 87, 81.2 % of peaople are having glucose lavel greater tha 125 and also having TenYearCHD == 1(YES) . And only 18.8 % of people are having less than 125 glucose lavel.\n",
        "\n",
        "Note: if glucose lavel is greater than 125 than the persion are suffering from diabetes."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "YEs: this idicates that id any people have more tha 125 glucose lavel than it have 88% chance to suffer from diabetes."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 : **`Variation in cholestrole and number of people whose cholestrole is greater than 200 and also suffering from CHD.`**"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this show the variation in Cholestrole.\n",
        "fig.ax=plt.subplots(figsize=(15,5))\n",
        "df.totChol[df.TenYearCHD==1].plot()\n",
        "plt.title('This show the variation in Cholesterol ', fontsize=13,fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GJQjMzZTfGMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "#this show the number of people whose cholestrole is greater than 200 and suffering from CHD.\n",
        "chol_ind=['Cholestrole < 200','CHD=yes','CHD=no']\n",
        "chol_value=[len(df.totChol[df.totChol<200]),len(df.totChol[(df.totChol<200)&(df.TenYearCHD==1)]),len(df.totChol[(df.totChol<200)&(df.TenYearCHD==0)])]\n",
        "fig, ax=plt.subplots()\n",
        "figure=ax.bar(chol_ind,chol_value)\n",
        "for index,value in enumerate(chol_value):\n",
        "  ax.text(x=index,y=value+5,s=value)\n",
        "figure[0].set_color('yellow')\n",
        "figure[1].set_color('red')\n",
        "figure[2].set_color('green')\n",
        "plt.title('Number of people whose cholestrol is < 200 and having or not having CHD proble',fontsize=8,fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variation in cholestrole and number of people whose cholestrole is greater tha 200 and also suffering from CHD."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. In the first chart we can see that the maximume cholestrole level is aprox 600 and minimum is 100.\n",
        "2. Here we can see that, there is 633 people's Cholestrole value is less than 200 and out of 633, 596 are not suffering from CHD and only 67 people is suffering from CHD."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes: here we oberve that the CHD is not much affected by cholestrole is no"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 : **`Here we plot the BLOOD PRESSURE with CHD.`**"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Heigh Blood Pressure means BP(sysBP/diaBP) is greater than sys=140/dia=90(1.55)\n",
        "\n",
        "HEIGH BP =sysBP/diaBP > 1.55\n",
        "\n",
        "NORMAL BP =sysBP/diaBP < 1.55"
      ],
      "metadata": {
        "id": "bx-_sQjXqjqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "bp_label=['Heigh BP','Normal BP']\n",
        "bp_value=[len(df[(df.TenYearCHD==0)&(df['sys-dia']>(140/90))]),len(df[(df.TenYearCHD==0)&(df['sys-dia']<(140/90))])]\n",
        "bp_value2=[len(df[(df.TenYearCHD==1)&(df['sys-dia']>(140/90))]),len(df[(df.TenYearCHD==1)&(df['sys-dia']<(140/90))])]\n",
        "fig, ax=plt.subplots(figsize=(7,4))\n",
        "fig1=ax.bar(bp_label,bp_value,color='#326da8')\n",
        "fig1=ax.bar(bp_label,bp_value2,color='red')\n",
        "for index, value in enumerate(bp_value):\n",
        "  ax.text(x=index,y=value+10,s=value)\n",
        "for index, value2 in enumerate(bp_value2):\n",
        "  ax.text(x=index,y=value2+10,s=value2)\n",
        "ax.text(x=0.75,y=1500,s='TenYearCHD==0 (NO)',fontdict={'color':'#326da8','fontweight':'bold'})\n",
        "ax.text(x=0.75,y=1400,s='TenYearCHD==1 (YES)',fontdict={'color':'red','fontweight':'bold'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "per_bp_ind=['TenYearCHD==1(YES)','TenYearCHD==0(NO)']\n",
        "per_bp_val=[len(df['sys-dia'][(df['sys-dia']>(140/90))&(df.TenYearCHD==1)]),len(df['sys-dia'][(df['sys-dia']>(140/90))&(df.TenYearCHD==0)])]\n",
        "plt.pie(per_bp_val,labels=per_bp_ind,autopct='%.2f',explode=(0,0.2),shadow=0.4)\n",
        "plt.title('Percentage of HEIGH BP peteint with CHD conditions',fontsize=10,fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OFeo_MqzqTnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we plot the BLOOD PRESSURE with CHD."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TenYearCHD == 0 (NO)**\n",
        "1. There is 1573 high blood pressure peteints.\n",
        "2. And 1306 Normal blood pressure peteints.\n",
        "\n",
        "**TenYearCHD == 1 (YES)**\n",
        "1. Here 348 people are high blood pressure and have CHD problem.\n",
        "2. only 163 people are Normal blood pressure and not having CHD problem.\n",
        "\n",
        "**Percentage of Heigh BP peteints with CHD conditions.**\n",
        "1. There is 81.83 % of people have high Blood Pressure but not having CHD problem.\n",
        "2. only 18.12 % pf people are high blood pressure and also having CHD problem in itiere dataset."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "YES."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 : **`Here we can see the number of peteint with Boody Mass Index and CHD.`**"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE** : Obesity, assessed using body mass index (BMI) >30 kg/m2, is an established risk factor for development of coronary heart disease (CHD) in healthy individuals."
      ],
      "metadata": {
        "id": "_M1gIWYpWhKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "bmi_label=['CHD==1(YES)','CHD==0(NO)']\n",
        "bmi_value=[len(df[(df.BMI>30)&(df.TenYearCHD==1)]),len(df[(df.BMI>30)&(df.TenYearCHD==0)])]\n",
        "fig, ax=plt.subplots()\n",
        "fig1=ax.bar(bmi_label,bmi_value)\n",
        "fig1[0].set_color('#e85151')\n",
        "fig1[1].set_color('#34eb7a')\n",
        "for index,value in enumerate(bmi_value):\n",
        "  ax.text(x=index,y=value+5,s=value)\n",
        "ax.text(x=-0.4,y=300,s=f\"Total people having BMI > 30 = {len(df[df.BMI>30])}\",fontdict={'fontsize':8,'fontweight':'bold','color':'blue'})\n",
        "plt.title('Number of peteint having BMI greater than 30',fontsize=10,fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see the number of peteint with Boody Mass Index and CHD."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is 436 people having BOODY MASS INDEX greater than 30 and in 436 only 82 are suffering from CHD and 354 are not suffering from CHD."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "YES."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 : **`Number of CHD patients who are in danger due to heart rate.`**"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**: Heart rate of <70 or ≥80 bpm was associated with an elevated risk of CV death among CHD patients."
      ],
      "metadata": {
        "id": "U1tbuUPPfr8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df[df.TenYearCHD==1]\n",
        "hrtr_label=['In danger','Out of danger']\n",
        "hrtr_value=[len(df2[(df2.heartRate<70)|(df.heartRate>80)]),len(df2[(df2.heartRate>70)&(df.heartRate<80)])]"
      ],
      "metadata": {
        "id": "wBKXJOfOes7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "fig,ax=plt.subplots()\n",
        "fig1=ax.bar(hrtr_label,hrtr_value)\n",
        "fig1[0].set_color('#cf2547')\n",
        "for ind,value in enumerate(hrtr_value):\n",
        "  ax.text(x=ind,y=value+5,s=value)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of CHD patients who are in danger due to heart rate."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Here 299 CHD patients are in danger condition because they have heart rate <70 or >=80 bpm.\n",
        "2. And only 127 patients are out of danger with heart rate."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes: becouse we know about the heart rate ."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 : **`Number of Hypertension and Stroke with Age.`**"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "hyp_label=df.age[df.prevalentHyp==1].value_counts().sort_index().index\n",
        "hyp_values=df.age[df.prevalentHyp==1].value_counts().sort_index().values\n",
        "stroke_label=df.age[df.prevalentStroke==1].value_counts().sort_index().index\n",
        "stroke_values=df.age[df.prevalentStroke==1].value_counts().sort_index().values\n",
        "fig,ax=plt.subplots(figsize=(10,5))\n",
        "fig1=ax.plot(hyp_label,hyp_values,color='blue')\n",
        "fig2=ax.plot(stroke_label,stroke_values,color='orange')\n",
        "ax.text(x=32,y=51,s=\"Prevalent HYPERTENSION -----\",fontdict={'color':'blue'})\n",
        "ax.text(x=32,y=48,s=\"Prevalent STROKE -----\",fontdict={'color':'orange'})\n",
        "plt.title('Number of Hypertension and Stroke with Age',fontsize=10,fontweight='bold')\n",
        "plt.xlabel('AGE',fontsize=10,fontweight='bold')\n",
        "plt.ylabel('NUMBER',fontsize=10,fontweight='bold')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of Hypertension and Stroke with Age."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Before the age of 35 the Hypertension value is nulll and after the age of 70 Hypertension value is null. And the hypertension is started from the age of 35 and end with the age 75 . And it is maximum in the age of 50 to 60 and before 50 the hypertension is gradually increasing the after 65 ut gradually dicreasing.\n",
        "2. The chance of attack of Stroke is between age 45 to 65. And the age if 50 to 60 number of stroke is maximum."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes: because we know about the rage of age where the number of hypertension and stroke is maximum and munimum."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13 : **`The relation between age and diabetes peteints.`**"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "d_label=df.age[df.diabetes==1].value_counts().sort_index().index\n",
        "d_values=df.age[df.diabetes==1].value_counts().sort_index().values\n",
        "fig,ax=plt.subplots(figsize=(10,5))\n",
        "fig1=ax.plot(d_label,d_values,color='blue')\n",
        "fig2=ax.bar(d_label,d_values,color='orange')\n",
        "for index,value in zip(d_label,d_values):\n",
        "  ax.text(x=index,y=value+0.2,s=value)\n",
        "# ax.text(x=32,y=51,s=\"Prevalent HYPERTENSION -----\",fontdict={'color':'blue'})\n",
        "# ax.text(x=32,y=48,s=\"Prevalent STROKE -----\",fontdict={'color':'orange'})\n",
        "# plt.title('Number of Hypertension and Stroke with Age',fontsize=10,fontweight='bold')\n",
        "plt.xlabel('AGE',fontsize=10,fontweight='bold')\n",
        "plt.ylabel('NUMBER',fontsize=10,fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This show the relation between age and diabetes peteints."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The maximum number of diabetic peteints are in the age of 47,52,5,8,62 and the age between 45 to 65."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes :"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 -**` Correlation Heatmap`**"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "fig,ax=plt.subplots(figsize=(15,7))\n",
        "fig=sns.heatmap(df.corr(), annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This show correlation between each variable."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. PrevalentHYP is heighly correlated to blood pressure (sys=0.7 and dia=0.61)\n",
        "2. daibetes is heighly correlated to glucose (0.62)\n",
        "3. age & cigsperday, diabp & sysbp is heighly negative correlated.\n",
        "4. TenyearCHD is slightly heigh correlated to only blood pressure."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 -**` Pair Plot `**"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df[['cigsPerDay','prevalentStroke','prevalentHyp','diabetes','totChol','BMI','sys-dia','TenYearCHD']])"
      ],
      "metadata": {
        "id": "TXYJYjVCb7Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart show the pairplot of some important variable of dataset ."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. totchol is lie between 100 to 400 maximum for each variable.\n",
        "2. BMI is also lies between 10 to 40 maximum time for each variable.\n",
        "3. cigsperday also lies between 0 to 40 for each variable."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0PcT_r1ksYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. is this all variable is normaly distributed or not?\n",
        "2. are any dependent variable present in dataset ?\n",
        "3. Check whether discrete variables are related or not ?"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here going to create a sample dataset for all hypothetical test."
      ],
      "metadata": {
        "id": "sGpzXPcvqOvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a sample dataset\n",
        "sample_dataset=dataset.sample(300)"
      ],
      "metadata": {
        "id": "o3Ymdx2Yxg4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1 : **`Normality test`**"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "null hypothesis= vraible is not normaly distributed.\n",
        "\n",
        "alternate hypothesis = variable is normaly distributed."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "for i in sample_dataset.select_dtypes(include=np.number).columns.tolist():\n",
        "  stats, p_value=shapiro(dataset[i])\n",
        "  if p_value>0.5:\n",
        "    print( i,\" is normaly distributed .\",\"\\n\",\"P_value is : \",p_value,\"\\n\",\"................\")\n",
        "  else:\n",
        "    print(i,' is not normaly distributed.',\"\\n\",\"P_value is : \",p_value,\"\\n\",\"................\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see the distribution of variable through hist plot."
      ],
      "metadata": {
        "id": "U2-yxq4SHSNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sample_dataset.select_dtypes(include=np.number).columns.tolist():\n",
        "  plt.hist(dataset[i])\n",
        "  plt.title(f\"{i}\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "zDw9qTbSGtVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**shapiro Test**"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check whether the considered data is normally distributed data or not."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2 : **`The strength and direction of association between two ranked variables. (variable dependency test)`**"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis : variable is not dependent to each other .\n",
        "\n",
        "Alternate hypothesis : variable is dependent to each other."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "s_data=sample_dataset[['sysBP','diaBP','totChol','BMI','glucose']]\n",
        "for i in s_data.select_dtypes(include = np.number).columns.tolist():\n",
        "  for j in s_data.select_dtypes(include = np.number).columns.tolist():\n",
        "    stat,p_value=spearmanr(dataset[i][0:50],dataset[j][0:50],nan_policy='omit')\n",
        "    if p_value>0.05:\n",
        "      pass\n",
        "    else:\n",
        "      if i!=j:\n",
        "        print(i,':',j)\n",
        "        print(\"p_value : \",p_value)\n",
        "        print(\"dependent variable\",\"\\n\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spearmanr**"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It basically gives the measure of monotonicity of the relation between two variables i.e. how well the relationship between two variables could be represented using a monotonic function.\n",
        "\n",
        "\n",
        "Dependent variable : means that variable which are highly correlated to each other."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3 : **` Check whether discrete variables are related  .`**"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check whether discrete variables are related, chi2 test can be used. We define:\n",
        "1. Null Hypothesis (H0): Two variables are independent.\n",
        "2. Alternate Hypothesis (H1): Two variables are not independent.\n",
        "\n",
        "We can use Chi2 test to get a p-value and check if a categorical variable is dependent or independent to the dependent variable. If the p value obtained is greater than 0.05 then we reject the null hypothesis, and accept the alternate hypothesis."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s_data=sample_dataset[['prevalentHyp','diabetes','BPMeds','prevalentStroke','sex','education','is_smoking','TenYearCHD']]"
      ],
      "metadata": {
        "id": "hcRr5U6Qi_uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_data.is_smoking=[1 if i == 'YES' else 0 for i in s_data.is_smoking]\n",
        "s_data.sex=[1 if j == 'M' else 0 for j in s_data.sex]"
      ],
      "metadata": {
        "id": "4wIa_wZq8MzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "C1ieAfgaO6Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chi2 scores\n",
        "chi_scores = chi2(s_data.drop(columns='TenYearCHD'),s_data['TenYearCHD'])\n",
        "chi_scores\n"
      ],
      "metadata": {
        "id": "LLFRzGF_TcYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P values for discrete features\n",
        "p_values = pd.Series(chi_scores[1],index = s_data.drop(columns='TenYearCHD').columns)\n",
        "p_values.sort_values(ascending = False , inplace = True)\n",
        "p_values"
      ],
      "metadata": {
        "id": "XKZ93CziQqES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting p values for chi2 test for discrete features\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.xscale('log')\n",
        "plt.xlabel('P-value')\n",
        "plt.title('P-value for discrete features')\n",
        "p_values.plot.barh()"
      ],
      "metadata": {
        "id": "3clhbnFeQ8k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Since prevalent hypertension column (prevalent_hyp) has the smallest p value, we can say that it is the most important feature (among the categorical independent variables) which determines  the outcome of the dependent variable.\n",
        "* The is_smoking feature has the highest p-value, which indicates that it is the least important feature (among categorical independent variables).\n",
        "* We can drop this column since we already have a column cigs_per_day, which gives the number of cigarettes smoked by the patient in a day. The patients who don't smoke have entered zero in this column."
      ],
      "metadata": {
        "id": "qIY2gxLYR5Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SuSjKVAopIUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chi2 test**"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check whether discrete variables are related or not ."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is the heatmap of null value in dataset."
      ],
      "metadata": {
        "id": "kGlOfRwBeabZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "sns.heatmap(dataset.isnull())"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`cigs_per_day`**"
      ],
      "metadata": {
        "id": "HoRCQS3dIX0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputing the missing values in the cigs_per_day\n",
        "dataset['cigsPerDay'] = dataset['cigsPerDay'].fillna(dataset[df['is_smoking']=='YES']['cigsPerDay'].median())"
      ],
      "metadata": {
        "id": "Godu3lol0Q72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`BPMeds`**"
      ],
      "metadata": {
        "id": "bqgXp_srIvx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filling the null value of BPMeds.\n",
        "#if sysBP>80 and diaBP >120 then petaints taking the BPMeds otherwise not taking BPMeds.\n",
        "dataset.BPMeds=np.where((dataset.diaBP>80)&(dataset.sysBP>120),dataset.BPMeds.fillna(1),dataset.BPMeds)\n",
        "dataset.BPMeds.fillna(0,inplace=True)"
      ],
      "metadata": {
        "id": "FGPz_6zje-FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`totChol`**"
      ],
      "metadata": {
        "id": "R2mW-S4TI2yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filling the null value with median of totChol.\n",
        "t_median=dataset.totChol.median()\n",
        "dataset.totChol.fillna(t_median,inplace=True)\n"
      ],
      "metadata": {
        "id": "9gamKNuKg8lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`BMI`**"
      ],
      "metadata": {
        "id": "Okc_Fd20I9AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filling the null value with median of BMI.\n",
        "m_BMI=dataset.BMI.median()\n",
        "dataset.BMI.fillna(m_BMI, inplace=True)"
      ],
      "metadata": {
        "id": "Xz1GI5shiSsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`heartRate`**"
      ],
      "metadata": {
        "id": "fGlncUmkJAq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#droping the null value of heartRate because there is only one null value present.\n",
        "dataset=dataset.dropna(subset='heartRate',axis=0)"
      ],
      "metadata": {
        "id": "TnslfZfpiqMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`education`**"
      ],
      "metadata": {
        "id": "33nsfLtPSvsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filling the null value of education with mode .\n",
        "e_mode=dataset.education.mode()\n",
        "dataset.education.fillna(e_mode[0],inplace=True)"
      ],
      "metadata": {
        "id": "nbrvU5WqSnar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`glucose`**"
      ],
      "metadata": {
        "id": "614Agi4pJHOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#here imputing the null vlaue of glucose by KNN imputer.\n",
        "print(f\"this is the mean before imputing the null vlaue : {dataset.glucose.mean()}\")\n",
        "imputer = KNNImputer(n_neighbors=10)\n",
        "imputed = imputer.fit_transform(dataset[['glucose']])\n",
        "dataset['glucose'] = pd.DataFrame(imputed, columns=dataset[['glucose']].columns)\n",
        "print(f\"this is the mean after imputing the null vlaue : {dataset.glucose.mean()}\")"
      ],
      "metadata": {
        "id": "iPXQ7pfr6yvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see the all null vlaue of dataset is fill now ."
      ],
      "metadata": {
        "id": "3dSCekLudxsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "ExpTt0gEQebO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see that one null vlaue is left becouse it is a disadvantage of KNN imputer . so we are going to drop by using drop fuction ."
      ],
      "metadata": {
        "id": "g2zx1OgOVkrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "id": "K8n02g7EVz2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(dataset.isnull())"
      ],
      "metadata": {
        "id": "WKdAM2O0Z-xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Missing value imputation*\n",
        "\n",
        "\n",
        "*   Cigs_per_day - filled the missing value with median of number of smoking value.\n",
        "*   BPMeds - if sysBP>80 and diaBP >120 then petaints taking the BPMeds otherwise not taking BPMeds.\n",
        "*   totalChol - with median of totChol.\n",
        "*   BMI - with median of BMI.\n",
        "*   heartRate - droping the null value of heartRate because there is only one null value present.\n",
        "*   education - with mode of education.\n",
        "*   glucose - here imputing the null vlaue of glucose by KNN imputer.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_num=dataset[['age','education','cigsPerDay','totChol','sysBP','diaBP','BMI','heartRate','glucose']]"
      ],
      "metadata": {
        "id": "-YQnRgUkajSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see the boxplot of each numerical columns of this dataset."
      ],
      "metadata": {
        "id": "_2rInxK9h7Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset_num.columns.tolist():\n",
        "  fig=go.Figure()\n",
        "  fig.add_trace(go.Box(x=dataset_num[i],name=i,fillcolor='green'))\n",
        "  fig.update_layout(\n",
        "    title_text=i,\n",
        "    title_x=0.5,\n",
        "    title_y=0.85,\n",
        "    title_font=dict(\n",
        "        color=\"blue\",\n",
        "        size=20,\n",
        "        family=\"Arial-bold\"\n",
        "      )\n",
        "    )\n",
        "  fig.show()\n"
      ],
      "metadata": {
        "id": "QrewSpixFpDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are going to impout the outliers through MODE in categorical columns and MEDIAN in continues columns."
      ],
      "metadata": {
        "id": "QLj_pzcFjbFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#here we can see the number of outlier in each columns\n",
        "for i in dataset_num.columns.tolist():\n",
        "  Q1,Q3=np.percentile(dataset_num[i],[25,75])\n",
        "  IQR = Q3-Q1\n",
        "  lower_fence=Q1-(1.5*IQR)\n",
        "  higher_fence=Q3+(1.5*IQR)\n",
        "  print(f\"{i}->\",f\"Less than lower fence : {len(dataset_num[dataset_num[i]<lower_fence][i])} |\",\n",
        "        f\"Greater than higher fence : {len(dataset_num[dataset_num[i]>higher_fence][i])} | \",\n",
        "        f\"Total number of outliers : {len(dataset_num[(dataset_num[i]<lower_fence) | (dataset_num[i]>higher_fence)][i])}\")"
      ],
      "metadata": {
        "id": "dMat64qYMS5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling the dataset with floor value and capp value .\n",
        "for j in dataset_num.columns.tolist():\n",
        "  Q1 = dataset[j].quantile(0.25)\n",
        "  Q3 = dataset[j].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  whisker_width = 1.5\n",
        "  lower_whisker = Q1 -(whisker_width*IQR)\n",
        "  upper_whisker = Q3 +(whisker_width*IQR)\n",
        "  dataset[j]=np.where(dataset[j]>upper_whisker,upper_whisker,np.where(dataset[j]<lower_whisker,lower_whisker,dataset[j]))\n",
        "  dataset_num[j]=np.where(dataset_num[j]>upper_whisker,upper_whisker,np.where(dataset_num[j]<lower_whisker,lower_whisker,dataset_num[j]))"
      ],
      "metadata": {
        "id": "MbMD6auIVo6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here we can see the number of outlier in each columns\n",
        "for i in dataset_num.columns.tolist():\n",
        "  Q1,Q3=np.percentile(dataset[i],[25,75])\n",
        "  IQR = Q3-Q1\n",
        "  lower_fence=Q1-(1.5*IQR)\n",
        "  higher_fence=Q3+(1.5*IQR)\n",
        "  print(f\"{i}->\",f\"Less than lower fence : {len(dataset_num[dataset_num[i]<lower_fence][i])} |\",\n",
        "        f\"Greater than higher fence : {len(dataset_num[dataset_num[i]>higher_fence][i])} | \",\n",
        "        f\"Total number of outliers : {len(dataset_num[(dataset_num[i]<lower_fence) | (dataset_num[i]>higher_fence)][i])}\")"
      ],
      "metadata": {
        "id": "t2JcMLtEaENi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Flooring And Capping**\n",
        "in this quantile-based technique, we will do the flooring(e.g 25th percentile) for the lower values and capping(e.g for the 75th percentile) for the higher values. These percentile values will be used for the quantile-based flooring and capping."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can only 2 feature are categorical feature .\n",
        "1. sex\n",
        "2. is_smoking"
      ],
      "metadata": {
        "id": "7OEItZnDstGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(5)"
      ],
      "metadata": {
        "id": "PBf1IGJen6FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are giong to replace ..\n",
        "1. sex : 'M' with 1 and 'F' with 0\n",
        "2. is_smoking : 'YES' with 1 and 'NO' with 0"
      ],
      "metadata": {
        "id": "EipOwlUQtBE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "dataset.sex=[1 if i == 'M' else 0 for i in dataset.sex]\n",
        "dataset.is_smoking=[1 if i == 'YES' else 0 for i in dataset.is_smoking]"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(5)"
      ],
      "metadata": {
        "id": "V3yKvh87uAGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we could have used Hotencoding as well but we use this\n",
        "\n",
        "we are giong to replace ..\n",
        "1. sex : 'M' with 1 and 'F' with 0\n",
        "2. is_smoking : 'YES' with 1 and 'NO' with 0\n",
        "\n",
        "becouse it perform better than hotencoding."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "dataset.index = dataset['id']\n",
        "dataset.drop('id',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=dataset.drop('TenYearCHD',axis=1)\n",
        "Y=dataset['TenYearCHD']"
      ],
      "metadata": {
        "id": "mlt1-lf3Kzi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"feature variable shape : \",X.shape)\n",
        "print(\"target variable shape : \",Y.shape)"
      ],
      "metadata": {
        "id": "_x0_8ndi5TSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here i colud also do some manipulation by deviding and multipling the tow columns , i tried but it not gave to good correlation value with label variable therefor i can use in main dataset."
      ],
      "metadata": {
        "id": "vkx2F-6tLv-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **`Random Forest Importance`**"
      ],
      "metadata": {
        "id": "sfC8Q1TiVnd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Importance"
      ],
      "metadata": {
        "id": "po2Ze-ANULHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_model=RandomForestClassifier(n_estimators=500)\n",
        "im_model.fit(X,Y)"
      ],
      "metadata": {
        "id": "b4aMGoDmVCkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imp=im_model.feature_importances_\n",
        "importance=pd.DataFrame()\n",
        "importance['value']=imp\n",
        "importance['columns']=X.columns\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Bar(x=importance['columns'],y=importance['value']))\n",
        "fig.update_layout(\n",
        "    title_text='RANDOM FOREST IMPORTANCE',\n",
        "    title_x=0.5,\n",
        "    title_y=0.85\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "0BV-acoFVOPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see clearly the importance of each feature in the model training."
      ],
      "metadata": {
        "id": "kwprHHM_Vt9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **`Wrapper Methods`**"
      ],
      "metadata": {
        "id": "l1oyfMLvV2zJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here total number of 15 columns we are going to drop one of them which is less affective for model trainig and 14 are remaing left in dataset which are important for the model trainig and also important for dataset."
      ],
      "metadata": {
        "id": "PPFPzyuCXBsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf=RandomForestClassifier(n_estimators=200)\n",
        "sfs=SFS(clf,n_features_to_select=14,n_jobs=-1)\n",
        "sfs.fit(X,Y)"
      ],
      "metadata": {
        "id": "ZbphUkCoWUOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{x: y for x, y in zip(X.columns.tolist(), sfs.get_support().tolist())}"
      ],
      "metadata": {
        "id": "rRUv6cI2xBna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the WRAPER method tell us drop those columns which have false value in front of the column name .\n",
        "\n",
        "**note:** we cant use this method in feature selection because this tell us to drop that column wich is important in CHD analysis. whereas droping that column is slightly increasing the score of the model still we cant drop it ."
      ],
      "metadata": {
        "id": "u7Qc1DGOyoN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **`Information Gain`**"
      ],
      "metadata": {
        "id": "JKGTMESy0pMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important=mutual_info_classif(X,Y)\n",
        "important_d=pd.DataFrame()\n",
        "important_d['value']=important\n",
        "important_d['columns']=X.columns"
      ],
      "metadata": {
        "id": "0C1OkL980b36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=go.Figure()\n",
        "fig.add_trace(go.Bar(x=important_d['columns'],y=important_d['value']))\n",
        "fig.update_layout(\n",
        "    title_text='INFORMATION GAIN',\n",
        "    title_x=0.5,\n",
        "    title_y=0.85\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "AJ0y5yXD0bkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOW HERE WE ARE GOING TO COMPAIR AND DECIDE TO WHICH COLUMN IS BEST FOR DROPING FROM DATASET ."
      ],
      "metadata": {
        "id": "AR4NeGwY3XPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig=go.Figure()\n",
        "fig.add_trace(go.Bar(x=p_values.index,y=p_values.values))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "W5xzqx-ZqlBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.tools import make_subplots\n",
        "fig=make_subplots(rows=1, cols=3)\n",
        "fig.add_trace(go.Bar(x=importance['columns'],y=importance['value'],name='Random forest importance'),row=1, col=1)\n",
        "fig.add_trace(go.Bar(x=important_d['columns'],y=important_d['value'],name='Information gain'),row=1, col=2)\n",
        "fig.add_trace(go.Bar(x=p_values.index,y=p_values.values,name='Chi2 test'),row=1, col=3)\n",
        "fig.update_layout(\n",
        "    title_text='COMPERISION BTWEEN {RANDOM FOREST IMPORTANCE, INFORMATION GAIN, Chi2 }',\n",
        "    title_x=0.44,\n",
        "    title_y=0.85\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "OqX9o2tL0bQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Here we are going to drop the `'is_smoking'` column because it give low information gain, also showing low importance in model training.\n",
        "* and in chi2 test we can clearly see that the 'is_smoking' have highest number of p_value."
      ],
      "metadata": {
        "id": "Jsz9Lxl20Jjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.drop('is_smoking',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "IJIArVqe0HT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "id": "y0F6BDUU0jxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **`Random Forest Importance`** : Random Forests is a kind of Bagging Algorithm that aggregates a specified number of decision trees. The tree-based strategies used by random forests naturally rank by how well they improve the purity of the node, or in other words, a decrease in the impurity (Gini impurity) over all trees. Nodes with the greatest decrease in impurity happen at the start of the trees, while notes with the least decrease in impurity occur at the end of the trees. Thus, by pruning trees below a particular node, we can create a subset of the most important features.\n",
        "2. **`Wrapper Methods`** : Wrappers require some method to search the space of all possible subsets of features, assessing their quality by learning and evaluating a classifier with that feature subset. The feature selection process is based on a specific machine learning algorithm we are trying to fit on a given dataset. It follows a greedy search approach by evaluating all the possible combinations of features against the evaluation criterion. The wrapper methods usually result in better predictive accuracy than filter methods.\n",
        "3. **`Information Gain`** : Information gain calculates the reduction in entropy from the transformation of a dataset. It can be used for feature selection by evaluating the Information gain of each variable in the context of the target variable."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'age', 'education', 'sex', 'is_smoking', 'cigsPerDay',\n",
        "       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n",
        "       'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD'\n",
        "\n",
        "These are the important feature because this show high information gain and hiegh importance in model training .\n",
        "\n"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "continuous_var=['age','cigsPerDay','totChol','sysBP','diaBP','BMI','heartRate','glucose']"
      ],
      "metadata": {
        "id": "tcupU2nLflOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**cheacking skewness in continiuous veriable**"
      ],
      "metadata": {
        "id": "EbKdqJe-gLKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# skewness along the index axis\n",
        "(X[continuous_var]).skew(axis = 0)"
      ],
      "metadata": {
        "id": "sTCSZ8RyfrvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can clearly see that the features are normaly distributed ."
      ],
      "metadata": {
        "id": "H2uA61pwjuSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ploting the skewness of variable\n",
        "for i in continuous_var:\n",
        "   plt.figure(figsize=(10,5))\n",
        "   sns.histplot(dataset[i],kde=True)\n",
        "   plt.title(i,fontsize=15,fontweight='bold')\n",
        "   plt.show()"
      ],
      "metadata": {
        "id": "ilhZ-FkUgTHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "maximum features are right skwed."
      ],
      "metadata": {
        "id": "uhya0PaMj5uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Many continuous variables are skewed. By log transformation, we aim to reduce the magnitude of skew in these variables to a certain extent.**"
      ],
      "metadata": {
        "id": "dS78j8GKf6y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Skew for log10 transformation**"
      ],
      "metadata": {
        "id": "hkTWkCM6guat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# log10 transformation\n",
        "X[continuous_var]=np.log10(X[continuous_var]+1)"
      ],
      "metadata": {
        "id": "E6pYc7NAYQUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking skew after log transformation\n",
        "X[continuous_var].skew(axis = 0)"
      ],
      "metadata": {
        "id": "GfCkZQBmiDFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in continuous_var:\n",
        "   plt.figure(figsize=(10,5))\n",
        "   sns.histplot(dataset[i],kde=True)\n",
        "   plt.title(i,fontsize=15,fontweight='bold')\n",
        "   plt.show()"
      ],
      "metadata": {
        "id": "8pzG1XPchp32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***we have successfully been able to reduce the skewness in the continuous variables. Now these distributions are closer to symmetric distribution.***"
      ],
      "metadata": {
        "id": "NOzvdKaRkFxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "scale= StandardScaler()\n",
        "x=scale.fit_transform(X)\n",
        "x=pd.DataFrame(x,columns=X.columns)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MinMaxScaler : its default scale for the MinMaxScaler is to rescale variables into the range [0,1]. and we are going to use default scaling ."
      ],
      "metadata": {
        "id": "HXUc9Zdg6REC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NO, because there is not large number of feature avilabe and we can try for '**`diaBP`**' and '**`sysBP`**' but when i combine them i got very low correlation for that feature therefor i am not going to do any Dimensionality reduction in this dataset."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "train_x,test_x,train_y,test_y=train_test_split(x,Y,test_size=0.3, random_state=0, stratify=Y, shuffle=True)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train|test=8|3 , because i want to give more data to model for training."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes : because here we can see in target variable the len of '0' is 2193 and '1' is 403 only ."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.value_counts()"
      ],
      "metadata": {
        "id": "vnpQekXTwzqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=go.Figure()\n",
        "fig.add_trace(go.Bar(x=[0,1],y=[len(train_y[train_y==0]),len(train_y[train_y==1])]))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "dxosAEogvJOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "smote=SMOTETomek(random_state=42)\n",
        "x_train,y_train=smote.fit_resample(train_x,train_y)\n",
        "test_x,test_y=smote.fit_resample(test_x,test_y)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=go.Figure()\n",
        "fig.add_trace(go.Bar(x=[0,1],y=[len(y_train[y_train==0]),len(y_train[y_train==1])]))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "3YMTbsEvxZZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "how here dataset is balanced ."
      ],
      "metadata": {
        "id": "RwR-6Hqrxm--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **SMOTETomek** is somewhere upsampling and downsampling. SMOTETomek is a hybrid method which is a mixture of the above two methods, it uses an under-sampling method (Tomek) with an oversampling method (SMOTE).\n",
        "2. Here i create new data compearing the target variable and labeled varables ."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 : **`KNeighborsClassifier`**"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "model1=KNeighborsClassifier()\n",
        "# Fit the Algorithm\n",
        "model1.fit(x_train,y_train)\n",
        "# Predict on the model\n",
        "model1_predict=model1.predict(test_x)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(f\"---------------------------------This is the score of model1 : {accuracy_score(test_y,model1_predict)} ---------------------------------\")"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confussion matrix.\n",
        "skplt.metrics.plot_confusion_matrix(test_y, model1_predict, normalize=False, title = 'Confusion Matrix for model1(KNeighborsClassifier)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dIg0GgWM5a2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"This is the precision score of that metrics  : {precision_score(test_y,model1_predict)}\")\n",
        "print(f\"This is the Recall score of that metrics  : {recall_score(test_y,model1_predict)}\")"
      ],
      "metadata": {
        "id": "vnbabcRy9-Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size,train_score,test_score=learning_curve(model1,x_train,y_train,scoring='accuracy',train_sizes=np.linspace(0.01,1,50),n_jobs=-1)\n",
        "train_mean=train_score.mean(axis=1)\n",
        "train_std=train_score.std(axis=1)\n",
        "test_mean=test_score.mean(axis=1)\n",
        "test_std=test_score.std(axis=1)\n",
        "\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=train_size,y=train_mean,name='Training score'))\n",
        "fig.add_trace(go.Scatter(x=train_size,y=test_mean,name ='Testing score (cv)'))\n",
        "fig.add_trace(go.Scatter(x = train_size,y = train_mean + train_std,line_color = 'gray',showlegend=False,name = 'Upper band',opacity = 0.5),)\n",
        "fig.add_trace(go.Scatter(x = train_size, y = train_mean - train_std , line_color = 'gray', fill = 'tonexty', name = 'Lower band', showlegend=False, opacity = 0.5),)\n",
        "fig.add_trace(go.Scatter(x = train_size, y = test_mean + test_std,  line_color = 'gray',  name = 'upper band',  showlegend=False,  opacity = 0.5),)\n",
        "fig.add_trace(go.Scatter(x = train_size, y = test_mean-test_std, line_color = 'gray', fill = 'tonexty', name = 'Lower band', showlegend=False, opacity = 0.5),)\n",
        "fig.update_layout(title_text='LEARNING CURVE WITH VARIOUS TRAINING SHAPE',title_x=0.5,title_y=0.85)\n",
        "fig.update_yaxes(title_text='MODEL SCORE')\n",
        "fig.update_xaxes(title_text='SHAPE OF TRAINING DATASET')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "upXFNo4UWwrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see after 1000 data the score of model is varing constatly , this show that increament of data will not going to improve the score of model."
      ],
      "metadata": {
        "id": "dvynpSo6tXOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "k_range = list(range(1, 31))\n",
        "param_grid = dict(n_neighbors=k_range)\n",
        "grid = GridSearchCV(model1, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
        "# Fit the Algorithm\n",
        "grid_search=grid.fit(x_train, y_train)\n",
        "# Predict on the model\n",
        "print(f\"Best parameter for this model -  {grid_search.best_params_}\")\n",
        "print(f\"Best score for this model -  {grid_search.best_score_ *100}\")"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix of grid model.\n",
        "model_1=KNeighborsClassifier(n_neighbors=2)\n",
        "model_1.fit(x_train,y_train)\n",
        "model_1_predict=model_1.predict(test_x)\n",
        "skplt.metrics.plot_confusion_matrix(test_y, model_1_predict, normalize=False, title = 'Confusion Matrix for model1(KNeighborsClassifier)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oayJ4vo3zN6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is the classification report for model 2\n",
        "print(classification_report(test_y,model_1_predict))"
      ],
      "metadata": {
        "id": "pGQQuF55yE8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"This is the precision score of that metrics  : {precision_score(test_y,model_1_predict)}\")\n",
        "print(f\"This is the Recall score of that metrics  : {recall_score(test_y,model_1_predict)}\")"
      ],
      "metadata": {
        "id": "ycQ1MEdT8P2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***`ROC_AUC`***"
      ],
      "metadata": {
        "id": "T4mCJBJIgFpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_scores = model1.predict_proba(test_x)\n",
        "fpr, tpr, threshold = roc_curve(test_y, y_scores[:, 1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=[0,1],y=[0,1],name=\"Normal line\",mode='lines'))\n",
        "fig.add_trace(go.Scatter(x=fpr,y=tpr,fill='tonexty',mode='none',name=f\"KNeighborsClassifier-ROC-AUC : {round(roc_auc,2)}\"))\n",
        "fig.update_layout(title_text=\"ROC curve of KNN\",\n",
        "                  title_x=0.4,title_y=0.85,\n",
        "                  title_font=dict(\n",
        "                     color=\"blue\",\n",
        "                     family='bold',\n",
        "                     size=17\n",
        "                  ))\n",
        "fig.update_xaxes(\n",
        "    title_text=\"False Positive Rate\",\n",
        "    title_font=dict(\n",
        "        color='blue',\n",
        "        family='bold',\n",
        "        size=14\n",
        "    )\n",
        ")\n",
        "fig.update_yaxes(\n",
        "    title_text=\"True Positive Rate\",\n",
        "    title_font=dict(\n",
        "        color='blue',\n",
        "        family='bold',\n",
        "        size=14\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "50-MBHbAfpcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n",
        "\n",
        "* True Positive Rate\n",
        "* False Positive Rate"
      ],
      "metadata": {
        "id": "aRf7UfWvlWCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GridSearchCV:** GridSearchCV tries all the combinations of the values passed in the dictionary and evaluates the model for each combination using the Cross-Validation method. Hence after using this function we get accuracy/loss for every combination of hyperparameters and we can choose the one with the best performance."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. score is improve little bit but.\n",
        "2. confussion matrix showing not to good for `Recall`."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 : **`RandomForestClassifier`**"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "model2=RandomForestClassifier()\n",
        "# Fit the Algorithm\n",
        "model2.fit(x_train,y_train)\n",
        "# Predict on the model\n",
        "model2_predict=model2.predict(test_x)"
      ],
      "metadata": {
        "id": "ISim1njq2Sr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(f\"---------------------------------This is the score of model1 : {accuracy_score(test_y,model2_predict)} ---------------------------------\")"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confussion matrix.\n",
        "skplt.metrics.plot_confusion_matrix(test_y, model2_predict, normalize=False, title = 'Confusion Matrix for model2(RandomForestClassifier)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CLwa-cK33LSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"This is the precision score of that metrics  : {precision_score(test_y,model2_predict)}\")\n",
        "print(f\"This is the Recall score of that metrics  : {recall_score(test_y,model2_predict)}\")"
      ],
      "metadata": {
        "id": "22HXeT3T41Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#learning curve\n",
        "train_size,train_score,test_score=learning_curve(model2,x_train,y_train,scoring='accuracy',train_sizes=np.linspace(0.01,1,50),n_jobs=-1)\n",
        "train_mean=train_score.mean(axis=1)\n",
        "train_std=train_score.std(axis=1)\n",
        "test_mean=test_score.mean(axis=1)\n",
        "test_std=test_score.std(axis=1)\n",
        "\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=train_size,y=train_mean,name='Training score'))\n",
        "fig.add_trace(go.Scatter(x=train_size,y=test_mean,name ='Testing score (cv)'))\n",
        "fig.add_trace(go.Scatter(x = train_size,y = train_mean + train_std,line_color = 'gray',showlegend=False,name = 'Upper band',opacity = 0.5),)\n",
        "fig.add_trace(go.Scatter(x = train_size, y = train_mean - train_std , line_color = 'gray', fill = 'tonexty', name = 'Lower band', showlegend=False, opacity = 0.5),)\n",
        "fig.add_trace(go.Scatter(x = train_size, y = test_mean + test_std,  line_color = 'gray',  name = 'upper band',  showlegend=False,  opacity = 0.5),)\n",
        "fig.add_trace(go.Scatter(x = train_size, y = test_mean-test_std, line_color = 'gray', fill = 'tonexty', name = 'Lower band', showlegend=False, opacity = 0.5),)\n",
        "fig.update_layout(title_text='LEARNING CURVE WITH VARIOUS TRAINING SHAPE',title_x=0.5,title_y=0.85)\n",
        "fig.update_yaxes(title_text='MODEL SCORE')\n",
        "fig.update_xaxes(title_text='SHAPE OF TRAINING DATASET')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ed9lXA9K5QIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After 3500 data of training dataset the learning curve is moving constantly ."
      ],
      "metadata": {
        "id": "-YX537s79ILo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_dict={\n",
        " 'max_features': ['sqrt'],\n",
        " 'n_estimators': [15,20,25,300],\n",
        " 'max_depth':[10,20,30,40],\n",
        " }\n",
        "model2_grid_search = GridSearchCV(model2, param_dict, cv = 5, scoring='accuracy')\n",
        "# Fit the Algorithm\n",
        "model2_grid_search.fit(x_train,y_train)\n",
        "# Predict on the model\n",
        "print(f\"\\n\\nBest parameter for this model -  {model2_grid_search.best_params_}\")\n",
        "print(f\"Best score for this model -  {model2_grid_search.best_score_ *100}\")"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#after hypermetertuning we are going to use this tuned hypermeter into model training\n",
        "model_2=RandomForestClassifier(bootstrap= False,max_features= 'sqrt', n_estimators= 500,max_depth=30)\n",
        "model_2.fit(x_train,y_train)\n",
        "model_2_predict=model_2.predict(test_x)\n",
        "skplt.metrics.plot_confusion_matrix(test_y, model_2_predict, normalize=False, title = 'Confusion Matrix for model2(RandomForestClassifier)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ViKj0qxU9iny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is the classification report for model 2\n",
        "print(classification_report(test_y,model_2_predict))"
      ],
      "metadata": {
        "id": "XM6ffHtgu59r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***`ROC-AUC`***"
      ],
      "metadata": {
        "id": "NQYzfLq7Lfx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_scores = model2.predict_proba(test_x)\n",
        "fpr_r, tpr_r, threshold = roc_curve(test_y, y_scores[:, 1])\n",
        "roc_auc_r = auc(fpr_r, tpr_r)\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=[0,1],y=[0,1],name=\"Normal line\",mode='lines'))\n",
        "fig.add_trace(go.Scatter(x=fpr_r,y=tpr_r,fill='tonexty',mode='none',name=f\"RandomForestClassifier-ROC-AUC : {round(roc_auc_r,2)}\"))\n",
        "fig.update_layout(title_text=\"ROC curve of Random Forest\",\n",
        "                  title_x=0.4,title_y=0.85,\n",
        "                  title_font=dict(\n",
        "                     color=\"blue\",\n",
        "                     family='bold',\n",
        "                     size=17\n",
        "                  ))\n",
        "fig.update_xaxes(\n",
        "    title_text=\"False Positive Rate\",\n",
        "    title_font=dict(\n",
        "        color='blue',\n",
        "        family='bold',\n",
        "        size=14\n",
        "    )\n",
        ")\n",
        "fig.update_yaxes(\n",
        "    title_text=\"True Positive Rate\",\n",
        "    title_font=dict(\n",
        "        color='blue',\n",
        "        family='bold',\n",
        "        size=14\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "-XCvq6MglaMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n",
        "\n",
        "* True Positive Rate\n",
        "* False Positive Rate"
      ],
      "metadata": {
        "id": "61fdxyibniK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GridSearchCV:** GridSearchCV tries all the combinations of the values passed in the dictionary and evaluates the model for each combination using the Cross-Validation method. Hence after using this function we get accuracy/loss for every combination of hyperparameters and we can choose the one with the best performance."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. macro Precision = 0.80\n",
        "2. macro Recall = 0.82\n",
        "\n",
        "Here recall and precision going equavalent to each other .this is positive improvment of model."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see the Recall and Precision  of confusion metrics is not as good as we want therefore we have to do **Precision Recall Tradoff** at the end of model selectioin"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 : **`DecisionTreeClassifier`**"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "model3=DecisionTreeClassifier()\n",
        "# Fit the Algorithm\n",
        "model3.fit(x_train,y_train)\n",
        "# Predict on the model\n",
        "model3_predict=model3.predict(test_x)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(f\"---------------------------------This is the score of model1 : {accuracy_score(test_y,model3_predict)} ---------------------------------\")"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confussion matrix.\n",
        "skplt.metrics.plot_confusion_matrix(test_y, model3_predict, normalize=False, title = 'Confusion Matrix for model3(DecisionTreeClassifier)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oR8sSU084FAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"This is the precision score of that metrics  : {precision_score(test_y,model3_predict)}\")\n",
        "print(f\"This is the Recall score of that metrics  : {recall_score(test_y,model3_predict)}\")"
      ],
      "metadata": {
        "id": "BAPX1qaoBR-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "params =  {\n",
        "    'criterion':['gini','entropy'],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_depth': [1, 2, 3 ,None]\n",
        "}\n",
        "grid = GridSearchCV(estimator=model3,\n",
        "                    param_grid=params,\n",
        "                    cv=10,\n",
        "                    n_jobs=1,\n",
        "                    verbose=2,\n",
        "                    error_score='raise')\n",
        "# Fit the Algorithm\n",
        "grid.fit(x_train, y_train)\n",
        "# Predict on the model\n",
        "print(f\"Best score : {grid.best_score_}\")\n",
        "print(f\"Best parameters : {grid.best_params_}\")"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3=DecisionTreeClassifier(criterion='entropy',max_depth=None,min_samples_leaf=1)\n",
        "model_3.fit(x_train,y_train)\n",
        "model_3_predict=model_3.predict(test_x)\n",
        "#confussion matrix.\n",
        "skplt.metrics.plot_confusion_matrix(test_y, model_3_predict, normalize=False, title = 'Confusion Matrix for model3(DecisionTreeClassifier)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OCOmxT22QxUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is the classification report for model 2\n",
        "print(classification_report(test_y,model_2_predict))"
      ],
      "metadata": {
        "id": "52qHlBjWyQr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"This is the precision score of that metrics  : {precision_score(test_y,model_3_predict)}\")\n",
        "print(f\"This is the Recall score of that metrics  : {recall_score(test_y,model_3_predict)}\")"
      ],
      "metadata": {
        "id": "acoVrbeqR8vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#learning cureve\n",
        "#learning curve\n",
        "train_size,train_score,test_score=learning_curve(model_3,x_train,y_train,scoring='accuracy',train_sizes=np.linspace(0.01,1,50),n_jobs=-1)\n",
        "train_mean=train_score.mean(axis=1)\n",
        "train_std=train_score.std(axis=1)\n",
        "test_mean=test_score.mean(axis=1)\n",
        "test_std=test_score.std(axis=1)\n",
        "\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=train_size,y=train_mean,name='Training score'))\n",
        "fig.add_trace(go.Scatter(x=train_size,y=test_mean,name ='Testing score (cv)'))\n",
        "fig.add_trace(go.Scatter(x = train_size,y = train_mean + train_std,line_color = 'gray',showlegend=False,name = 'Upper band',opacity = 0.5),)\n",
        "fig.add_trace(go.Scatter(x = train_size, y = train_mean - train_std , line_color = 'gray', fill = 'tonexty', name = 'Lower band', showlegend=False, opacity = 0.5),)\n",
        "fig.add_trace(go.Scatter(x = train_size, y = test_mean + test_std,  line_color = 'gray',  name = 'upper band',  showlegend=False,  opacity = 0.5),)\n",
        "fig.add_trace(go.Scatter(x = train_size, y = test_mean-test_std, line_color = 'gray', fill = 'tonexty', name = 'Lower band', showlegend=False, opacity = 0.5),)\n",
        "fig.update_layout(title_text='LEARNING CURVE WITH VARIOUS TRAINING SHAPE',title_x=0.5,title_y=0.85)\n",
        "fig.update_yaxes(title_text='MODEL SCORE')\n",
        "fig.update_xaxes(title_text='SHAPE OF TRAINING DATASET')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_DQfemN9SFFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that the testing score is increasing gradualy this show that if we increase the data in training the testing score will also improve ."
      ],
      "metadata": {
        "id": "nldguM-6TUN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_scores = model3.predict_proba(test_x)\n",
        "fpr_d, tpr_d, threshold = roc_curve(test_y, y_scores[:, 1])\n",
        "roc_auc_d = auc(fpr_d, tpr_d)\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=[0,1],y=[0,1],name=\"Normal line\",mode='lines'))\n",
        "fig.add_trace(go.Scatter(x=fpr_d,y=tpr_d,fill='tonexty',mode='none',name=f\"DecisionTreeClassifier-ROC-AUC : {round(roc_auc_d,2)}\"))\n",
        "fig.update_layout(title_text=\"ROC curve of Decision Tree\",\n",
        "                  title_x=0.4,title_y=0.85,\n",
        "                  title_font=dict(\n",
        "                     color=\"blue\",\n",
        "                     family='bold',\n",
        "                     size=17\n",
        "                  ))\n",
        "fig.update_xaxes(\n",
        "    title_text=\"False Positive Rate\",\n",
        "    title_font=dict(\n",
        "        color='blue',\n",
        "        family='bold',\n",
        "        size=14\n",
        "    )\n",
        ")\n",
        "fig.update_yaxes(\n",
        "    title_text=\"True Positive Rate\",\n",
        "    title_font=dict(\n",
        "        color='blue',\n",
        "        family='bold',\n",
        "        size=14\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "tuvd3ldpn0YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n",
        "\n",
        "* True Positive Rate\n",
        "* False Positive Rate"
      ],
      "metadata": {
        "id": "7msn_pHooohC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GridSearchCV:** GridSearchCV tries all the combinations of the values passed in the dictionary and evaluates the model for each combination using the Cross-Validation method. Hence after using this function we get accuracy/loss for every combination of hyperparameters and we can choose the one with the best performance."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes here we can see the improvment in score and in metrics."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cnofusion metrics , because it show the precision and recall of the model which is important for our prediction . and our aim is to improve more Recall value of model."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = PrettyTable(['Sl. No.','Classification Model','Test Recall (%)'])\n",
        "test.add_row(['1','K Nearest Neighbors',recall_score(test_y,model1_predict)*100])\n",
        "test.add_row(['2','Random Forest',recall_score(test_y,model2_predict)*100])\n",
        "test.add_row(['3','Decision Tree',recall_score(test_y,model3_predict)*100])\n",
        "print(test)"
      ],
      "metadata": {
        "id": "TEwoplTKDjVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`The recall score here is almost same for each model`**"
      ],
      "metadata": {
        "id": "Fto5JCaQty7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=[0,1],y=[0,1],name=\"Normal line\",mode='lines'))\n",
        "fig.add_trace(go.Scatter(x=fpr,y=tpr,fill='tonexty',mode='none',name=f\"KNeighborsClassifier-ROC-AUC : {round(roc_auc,2)}\"))\n",
        "fig.add_trace(go.Scatter(x=fpr_r,y=tpr_r,fill='tonexty',mode='none',name=f\"RandomForestClassifier-ROC-AUC : {round(roc_auc_r,2)}\"))\n",
        "fig.add_trace(go.Scatter(x=fpr_d,y=tpr_d,fill='tonexty',mode='none',name=f\"DecisionTreeClassifier-ROC-AUC : {round(roc_auc_d,2)}\"))\n",
        "\n",
        "fig.add_annotation(x=fpr[4], y=tpr[4],text=\"KNeighborsClassifier\",bgcolor=\"violet\",showarrow=True,arrowhead=1)\n",
        "fig.add_annotation(x=fpr_r[45], y=tpr_r[45],text=\"Random Forest\",bgcolor=\"violet\",showarrow=True,arrowhead=1)\n",
        "fig.add_annotation(x=fpr_d[1], y=tpr_d[1],text=\"Decisioin Tree\",bgcolor=\"violet\",showarrow=True,arrowhead=1)\n",
        "\n",
        "fig.update_layout(title_text='ROC - CURVE',title_x=0.4,title_y=0.85,title_font=dict(color='blue',family='bold',size=17))\n",
        "fig.update_xaxes(title_text='False Positive Rate',title_font=dict(color='blue',family='bold',size=17))\n",
        "fig.update_yaxes(title_text='True Positive Rate',title_font=dict(color='blue',family='bold',size=17))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "YzXW7n9yLRnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`No perfect models here, but all of them are far away from the baseline (unusable model). The random forest algorithm is the best, with a 0.82 AUC score.`**"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Explaining the Model using `: **`SHAP`**"
      ],
      "metadata": {
        "id": "2uRo1TPwzQAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXTRACTING THE FEATURE IMPORTANCE WITH SHAP ..."
      ],
      "metadata": {
        "id": "GKYseQJGV7on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prepearing explainer\n",
        "\n",
        "explainer = TreeExplainer(model_2)\n",
        "sv = explainer(x_train[:1000])"
      ],
      "metadata": {
        "id": "w1sycsnc1gjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s see which feature are the most important when determining TenYearCHD:\n",
        "shap.summary_plot(sv.values[:,:,1], x_train[:1000],cmap = \"plasma\",plot_type=\"bar\")"
      ],
      "metadata": {
        "id": "TK_ub9nfggyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature importance\n",
        "1. The age,Blood pressure out as the driving factor for TenYearCHD.\n",
        "2. and diabetes and prevalentStroke is least afecting factor for TenYearCHD."
      ],
      "metadata": {
        "id": "mPeEGeDZyoQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we can see which feature positively or negatively influences the model.\n",
        "shap.summary_plot(sv.values[:,:,1], x_train[:1000],cmap = \"plasma\")"
      ],
      "metadata": {
        "id": "Y7fU5Qb2Fjzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that as age increases, its effect on the model is more positive. The same is true for heartRate and Blood pressure feature. The totalChol, education and BMI features are a bit tricky with a cluster of mixed points around the center."
      ],
      "metadata": {
        "id": "U15YdXtcFqVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We can get a deeper insight into each feature’s effect on the entire dataset with dependence plots.\n",
        "shap.dependence_plot('age',sv.values[:,:,1],x_train[:1000],cmap = \"plasma\"),\n",
        "shap.dependence_plot('sysBP',sv.values[:,:,1],x_train[:1000],cmap = \"plasma\"),\n",
        "shap.dependence_plot('sex',sv.values[:,:,1],x_train[:1000],cmap = \"plasma\"),\n",
        "shap.dependence_plot('education',sv.values[:,:,1],x_train[:1000],cmap = \"plasma\"),\n",
        "shap.dependence_plot('glucose',sv.values[:,:,1],x_train[:1000],cmap = \"plasma\"),\n"
      ],
      "metadata": {
        "id": "AhZBOTkqqzkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that the 'age' interacts with the clarity of the diamonds much stronger than other features because of it has linierly ploted point.followed by 'Blood pressure' and others."
      ],
      "metadata": {
        "id": "_Teo7rEBMzA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explain_value = Explanation(sv.values[:,:,1],\n",
        "                  sv.base_values[:,1],\n",
        "                  data=x_train.values,\n",
        "                  feature_names=x_train.columns)"
      ],
      "metadata": {
        "id": "NFTPgKuJwOxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANALYSING THE MODEL PREDICTION BELOW..."
      ],
      "metadata": {
        "id": "n1gXzHGRUegS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#here we providing the index in which we want to analys the model prediction with features.\n",
        "idx = 59"
      ],
      "metadata": {
        "id": "-K9K68AawXj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let’s explain the random prob of that index we picked out with a waterfall plot\n",
        "shap.waterfall_plot(explain_value[idx])"
      ],
      "metadata": {
        "id": "3MTUAh-kgSwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The E[f(x)] = 0.5 is the mean prediction of TenYearCHD for the train set.The bars represent how each feature property shifted the price from the mean prediction. The red bars represent positive shifts; the blue bars represent negative shifts.\n",
        "\n",
        "* for index 59 - positivly increament in prob of features where totChol is 0.07 highest and then BMI, cigsperday and others.\n",
        "* And the prediction is 1 (yes)"
      ],
      "metadata": {
        "id": "Ug0dvhJXPBig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "shap.force_plot(explain_value[idx],plot_cmap = \"PkYg\")"
      ],
      "metadata": {
        "id": "WJN6Q69PPjih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is just an ordered, organized version of waterfall plots. All negative and positive bars are grouped to either side of the predicted price. Again, the base value shows the mean price, and the bars show how much each feature property shifts that value."
      ],
      "metadata": {
        "id": "S6ahg47PSjLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Age, Blood pressure, Sex thease three features are involving heigher in predicion of CHD.\n",
        "* Neither model has a good recall score. Therefore we can say that our model training is not on a point. So we can say that none of our models is suitable for business implementation ."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}